# Counter UAS
### Ewing, Boldt, Love, Jordan

## Recommended grade
A

## Advisor comments to the team
The team made good progress testing out machine vision and FFT code for detection of an opposing quadrotor, well ahead of what midshipmen normally do on such projects. I would have liked to have seen more flying or expeditious use of other platforms available through School of Drones / Midshipman Drone Racing Team and use of simulators (e.g. Liftoff, Realflight, Velocidrone, or DRL Simulator) to collect test imagery, or experimentation with a Tello or Anafi. I would also like to have seen tests with a thermal camera or thermal imagery from the internet, even if taken with some other camera. However, the team was not able to fully attack these areas due to covid and due to the format of EW401 (see below). 

One other area I would like to have seen some thinking in is to think more about developing pre-Milestone 0 (Milestone A) concepts of operations. The team immediately limited themselves to thinking about a single interceptor without thinking about the overall design of an air defense system in general. This locked them into certain concepts, and their three concept designs are mostly the same thing. The team did not delve deeply into thinking about threats or capabilities (in the sense of Defense Planning Guidance), instead locking in on an opposing force Anafi in the narrow sense of SWAT-C. In comparison, when I was working on deep submergence submarine concepts of operation, we thought more broadly about threats, missions, capabilities, and different ways to accomplish the various goals (along with tradeoffs and analyses of alternatives). 

I have been working on transferring your report to Latex and Github to allow collaborative editing. It would help immensely if you can provide your original figures as their native file formats. I will also direct, moving forward, that you do not use any templates or rubrics provided by other professors without discussing with me first. 

Minor comments will be handled via the Latex / Github repository. There are a few typos (e.g. CBDR is constant bearing, DECREASING range, minor formating issues). The budget states you discussed with me - which you did discuss the items needed; but I would have also asked you to include a disclaimer on the fake labor and overhead numbers which are done only for EW401 training purposes and should never be passed along to a sponsor without a disclaimer.  

## Advisor comments about EW401
I do not fault the guys for this, but I believe the way EW401 is conducted sets teams up to fail. At other universities (e.g. MIT 2.007, MIT 2.008, and MIT 2.009) the charts and tools are taught within the first few weeks of the sophomore design class (2.007) without much ado. Here they are dragged out, distracting students from actually getting their designs done. These guys needed to be flying and trying stuff in August but could not, partially due to covid, but also in large part due to the design of EW401. 

The format also unacceptably places the 401 instructor and course coordinator and a single customer in the prime position of shaping what the team does. As a result, I have less ability to guide them in the early phases of their project than others, even though ultimately I am the one who will have to help them finish and grade them at the end of capstone EW404. 

The class focus on designing a single widget is a poor fit for other things the student may have to design. I have been outspoken about this in the context of scientific research, but here the students were to design a weapons system -- and I actually have experience working on NR-1 replacement concepts, electric drive, submarine advance paylods, and VIRGINIA Class follow-on concepts. I was prevented from using that experience to guide these students. 

The rubrics and templates warp their thinking and should be eliminated. There is a ridiculous 6 page rubric this year - it seeems to grow by a page each year. If I tried to evaluate technical work at Naval Reactors using the course coordinator's 6 page rubric, my section head and ADM Bowman would have thrown a desk across the room. This department does not appreciate how real Navy acquisition professionals work (e.g. Naval Reactors, or the wider Naval Sea Systems Command) but their methods work. When they rename the building for a WRCE prof I will be happy to switch over but last I checked it's still Rickover Hall. 
  * Two "problem statement" headings
  * A PCC heading despite there being no PCC
  * All criteria graded 0-4 with no actual test data or raw numerics
  * Sketches only because we pushed really hard, no sketch models, no quick tests
  * Ethical considerations do not consider broader counter UAS (e.g. in populated areas)
  * Standards and specifications use ROHS and one MIL-STD because that's what they found. What value is added by this section? 
  * Fake numbers in budget directed by rubric and templates
  * WBS hours never tied to budget
  * During design presentations, blind use of an example presentation (even including nicknames for team members just because a team did that before)
  
I understand the need to learn the thought process used by engineers to do design work, but the emphasis here is solely on PROCESS and any THOUGHT is generally accidental. 

  
